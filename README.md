# ðŸŽŒ AniVerse-DB: Anime Tracker Database Project

![MySQL Version](https://img.shields.io/badge/MySQL-8.0-blue.svg?logo=mysql)
![Python Version](https://img.shields.io/badge/Python-3.10-blue.svg?logo=python)

This repository contains the complete database implementation for **AniVerse**, a conceptual anime list tracking platform (similar to *MyAnimeList*).
Developed as the final project for the **Introduction to Databases (DCC011)** course at **UFMG**.

The project focuses on **robust relational schema design**, **3NF normalization**, **SQL DDL/DML implementation**, and **query performance analysis**.

---

## ðŸ“œ Table of Contents

* [âœ¨ Key Features](#-key-features)
* [ðŸ› ï¸ Technology Stack](#%EF%B8%8F-technology-stack)
* [ðŸ—ï¸ Database Schema](#-database-schema)

  * [ðŸ“˜ EER Diagram](#eer-diagram)
  * [ðŸ§© Table Descriptions](#table-descriptions)
* [ðŸ“‚ File Structure](#-file-structure)
* [ðŸš€ Setup and Usage](#-setup-and-usage)

  * [ðŸ§± Prerequisites](#prerequisites)
  * [1ï¸âƒ£ Database Creation](#1-database-creation)
  * [2ï¸âƒ£ Run Test Data (Optional)](#2-run-test-data-optional)
  * [3ï¸âƒ£ Run Performance Analysis](#3-run-performance-analysis)
* [ðŸ” Database Access](#-database-access)
* [ðŸ“Š Query Performance Analysis](#-query-performance-analysis)

---

## âœ¨ Key Features

The schema supports the core functionalities of a modern anime tracking platform:

* **User Management:** User registration and profiles.
* **Anime Cataloging:** Detailed anime information with studio relations (`ESTUDIO`).
* **Personalized Tracking:** Custom user lists (`LISTA_USUARIO`) with status, rating, and episode progress.
* **Review System:** User-written reviews linked to `USUARIO` and `ANIME`.
* **Normalized Design:** Fully normalized (3NF), eliminating redundancy and ensuring data integrity.

---

## ðŸ› ï¸ Technology Stack

| Category                 | Tools                             |
| :----------------------- | :-------------------------------- |
| **Database**             | MySQL Server 8.0                  |
| **IDE & Design**         | MySQL Workbench                   |
| **Analysis & Scripting** | Python 3 (Google Colab / Jupyter) |
| **Connector**            | `mysql-connector-python`          |
| **Data Handling**        | `pandas`                          |

---

## ðŸ—ï¸ Database Schema

The schema was designed in **Third Normal Form (3NF)** to ensure consistency and scalability.
ER-to-relational mapping follows formal academic standards.

### ðŸ“˜ EER Diagram

*(Insert your exported diagram PNG/PDF here)*

> ðŸ–¼ï¸ *EER Diagram generated with MySQL Workbench*

### ðŸ§© Table Descriptions

| Table               | Purpose                                                    |
| :------------------ | :--------------------------------------------------------- |
| **`USUARIO`**       | Stores user profile information (ID, username, email).     |
| **`ESTUDIO`**       | Animation studio details (ID, name, founding year).        |
| **`ANIME`**         | Main anime catalog. Linked to `ESTUDIO` via FK.            |
| **`REVIEW`**        | User reviews linked to `USUARIO` and `ANIME`.              |
| **`ANIME_GENERO`**  | Handles M:N relationships for anime genres.                |
| **`LISTA_USUARIO`** | Core M:N table linking users and anime with tracking data. |

---

## ðŸ“‚ File Structure

```
ðŸ“¦ AniVerse-DB
â”œâ”€â”€ ðŸ“„ 01_criacao_esquema.sql                     # DDL: creates full schema (tables, FKs, constraints)
â”œâ”€â”€ ðŸ“„ 02_testes_e_amostras.sql                   # DML: sample/test data to validate schema
â”œâ”€â”€ ðŸ“˜ TP2_Implementacao_Consultas_Animes.ipynb   # Notebook for data loading (DML), all 10 analysis queries, and performance benchmarking.
â””â”€â”€ ðŸª¶ README.md                                  # Youâ€™re reading it now :)
```

---

## ðŸš€ Setup and Usage

Follow these steps to replicate the project and run your analysis.

### ðŸ§± Prerequisites

Make sure you have:

* âœ… **MySQL Server 8.0+**
* âœ… **MySQL Workbench** or equivalent client
* âœ… **Python 3.x** with:

  ```bash
  pip install pandas mysql-connector-python
  ```

---

### 1ï¸âƒ£ Database Creation

1. Open **MySQL Workbench** and connect to your MySQL instance.
2. Open the file `01_criacao_esquema.sql`.
3. Run the script (âš¡Execute All).
   â†’ This creates the full `animes_db` schema with all tables and constraints.

---

### 2ï¸âƒ£ Run Test Data (Optional)

1. Open `02_testes_e_amostras.sql` in MySQL Workbench.
2. Execute the entire script.
3. Verify the data:

   ```sql
   SELECT * FROM USUARIO;
   SELECT * FROM ANIME;
   ```

---

### 3ï¸âƒ£ Run Performance Analysis

1. Open the notebook `TP2_Implementacao_Consultas_Animes.ipynb` in **Google Colab** or **Jupyter**.
2. In the first cell (*ConfiguraÃ§Ã£o do Ambiente*), update:

   ```python
   DB_HOST = "your_host"
   DB_USER = "your_username"
   DB_PASSWORD = "your_password"
   DB_NAME = "animes_db"
   ```
3. Run all cells sequentially (`Runtime > Run all`).

The notebook will:

* Connect to your MySQL instance.
* Populate the database with a large volume of synthetic data (DML).
* Execute all 10 required analysis queries, each in at least two different formulations.
* Measure and benchmark the execution time of each query (averaged over 5 runs to avoid cold-start issues).
* Display the results and timings in formatted tables for easy comparison.

---

## ðŸ” Database Access

For academic integrity and data security reasons, **the original populated database (with full test dataset)** is **not publicly accessible**.

> If you would like to explore the original dataset or connect to the remote instance used for benchmarking, please **contact me directly** for access credentials.
> Sensitive information (e.g., passwords or host details) will only be shared upon verified request for educational purposes.

---

## ðŸ“Š Query Performance Analysis

Performance tests are detailed in the Jupyter notebook.
Each query is analyzed in two or more formulations to evaluate SQL efficiency.

**Metrics & Methodology**

* Each query runs 5 times (average execution time recorded).
* Topics include:

  * Simple projections and selections
  * 2-table and 3+ table joins
  * Aggregations with `GROUP BY`, `HAVING`, and nested subqueries
  * Query optimization and indexing impact

---
